# ArchtechTask1_LocalLLM
ðŸ’¬ Local LLM Chat App (Streamlit + Ollama)

A simple and interactive Streamlit web interface to chat with a locally installed large language model (LLM) using Ollama. The app allows you to input queries, get responses from the model, view conversation history, and reset the chat.

Features

Chat with a local LLM (Ollama) without the internet.

Conversation history panel in the sidebar.

Reset button to clear chat history.

Clean and interactive Streamlit interface.

Works fully offline once the model is installed.
